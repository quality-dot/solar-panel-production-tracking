import { LanguageModelV1, LanguageModelV1CallOptions, LanguageModelV1FunctionToolCall, LanguageModelV1FinishReason, LanguageModelV1CallWarning, LanguageModelV1StreamPart, ProviderV1 } from '@ai-sdk/provider';
export { LanguageModelV1, LanguageModelV1CallOptions, LanguageModelV1CallWarning, LanguageModelV1FinishReason, LanguageModelV1FunctionTool, LanguageModelV1FunctionToolCall, LanguageModelV1Message, LanguageModelV1Prompt, LanguageModelV1ProviderMetadata, LanguageModelV1StreamPart } from '@ai-sdk/provider';
import { GoogleAuth } from 'google-auth-library';

/**
 * Base options available for all authentication types
 */
interface BaseProviderOptions {
    /**
     * HTTP proxy URL to use for requests
     * Can also be set via HTTP_PROXY or HTTPS_PROXY environment variables
     */
    proxy?: string;
}
/**
 * Provider options for configuring Gemini authentication and behavior
 */
type GeminiProviderOptions = (GeminiApiKeyAuth & BaseProviderOptions) | (VertexAIAuth & BaseProviderOptions) | (OAuthAuth & BaseProviderOptions) | (GoogleAuthLibraryAuth & BaseProviderOptions) | ({
    authType?: undefined;
} & BaseProviderOptions);
/**
 * Gemini API key authentication (supports both AI SDK standard and Gemini-specific auth types)
 */
interface GeminiApiKeyAuth {
    authType: 'api-key' | 'gemini-api-key';
    apiKey?: string;
}
/**
 * Vertex AI authentication
 */
interface VertexAIAuth {
    authType: 'vertex-ai';
    vertexAI: {
        projectId: string;
        location: string;
        apiKey?: string;
    };
}
/**
 * OAuth authentication (personal or service account)
 */
interface OAuthAuth {
    authType: 'oauth' | 'oauth-personal';
    cacheDir?: string;
}
/**
 * Google Auth Library authentication
 */
interface GoogleAuthLibraryAuth {
    authType: 'google-auth-library';
    googleAuth?: GoogleAuth;
    googleAuthClient?: unknown;
}

interface GeminiLanguageModelOptions {
    modelId: string;
    providerOptions: GeminiProviderOptions;
    settings?: Record<string, unknown>;
}
declare class GeminiLanguageModel implements LanguageModelV1 {
    readonly specificationVersion: "v1";
    readonly provider = "gemini-cli-core";
    readonly defaultObjectGenerationMode: "json";
    readonly supportsImageUrls = false;
    readonly supportsStructuredOutputs = true;
    private contentGenerator?;
    private config?;
    private initPromise?;
    readonly modelId: string;
    readonly settings?: Record<string, unknown>;
    private providerOptions;
    constructor(options: GeminiLanguageModelOptions);
    private ensureInitialized;
    private initialize;
    /**
     * Non-streaming generation method
     */
    doGenerate(options: LanguageModelV1CallOptions): Promise<{
        text?: string;
        toolCalls?: LanguageModelV1FunctionToolCall[];
        finishReason: LanguageModelV1FinishReason;
        usage: {
            promptTokens: number;
            completionTokens: number;
        };
        rawCall: {
            rawPrompt: unknown;
            rawSettings: Record<string, unknown>;
        };
        rawResponse?: {
            headers?: Record<string, string>;
            body?: unknown;
        };
        request?: {
            body?: string;
        };
        response?: {
            id?: string;
            timestamp?: Date;
            modelId?: string;
        };
        warnings?: LanguageModelV1CallWarning[];
    }>;
    /**
     * Streaming generation method
     */
    doStream(options: LanguageModelV1CallOptions): Promise<{
        stream: ReadableStream<LanguageModelV1StreamPart>;
        rawCall: {
            rawPrompt: unknown;
            rawSettings: Record<string, unknown>;
        };
        rawResponse?: {
            headers?: Record<string, string>;
        };
        warnings?: LanguageModelV1CallWarning[];
    }>;
}

interface GeminiProvider extends ProviderV1 {
    (modelId: string, settings?: Record<string, unknown>): GeminiLanguageModel;
    languageModel(modelId: string, settings?: Record<string, unknown>): GeminiLanguageModel;
    chat(modelId: string, settings?: Record<string, unknown>): GeminiLanguageModel;
}
/**
 * Creates a new Gemini provider instance.
 *
 * @param options - Configuration options for the provider
 * @returns A configured provider function
 * @throws Error if authentication options are invalid
 *
 * @example
 * ```typescript
 * // Using API key authentication
 * const gemini = createGeminiProvider({
 *   authType: 'gemini-api-key',
 *   apiKey: process.env.GEMINI_API_KEY
 * });
 *
 * // Use with Vercel AI SDK
 * const model = gemini('gemini-1.5-flash');
 * const result = await generateText({
 *   model,
 *   prompt: 'Hello, world!'
 * });
 * ```
 */
declare function createGeminiProvider(options?: GeminiProviderOptions): GeminiProvider;

export { type GeminiProvider as GeminiCliCoreProvider, type GeminiProviderOptions as GeminiCliCoreProviderOptions, type GeminiProvider, type GeminiProviderOptions, createGeminiProvider as createGeminiCliCoreProvider, createGeminiProvider };
